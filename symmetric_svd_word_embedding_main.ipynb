{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import symmetric_svd_word_embedding_utilities as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whether consider the order of pmi\n",
    "pmi_order = False\n",
    "\n",
    "# threshold of rare unigram\n",
    "rare_term = 10\n",
    "\n",
    "# threshold of rare bigram\n",
    "rare_bigram = 5\n",
    "\n",
    "# dimension of matrix generated\n",
    "dimension = 100\n",
    "\n",
    "# value applied in laplace smooth\n",
    "la_smooth = 1\n",
    "\n",
    "# number of tweets deal with\n",
    "num_of_tweets = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mypath = './train_tweets'\n",
    "header_row = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the filenames are ***************************\n",
      "['tweets_senEval.txt']\n",
      "Original size of data is  49828\n",
      "after remove duplicate, the size is  49826\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = util.read_from_txt(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mypath = '../tweets_set_ire'\n",
    "# header_row = ['ID', 'ID_STR', 'author', 'text', 'time', 'location', 'latitude', 'longitude', 'screen_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_raw = util.read_from_csv(mypath,header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first row is*******************************\n",
      "text     Won the match #getin . Plus tomorrow is a very...\n",
      "label                                              neutral\n",
      "Name: 0, dtype: object\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the first row is*******************************')\n",
    "print(df_raw.iloc[0])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing tweet, remove mention, urls, emoji, strip each token and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tweet_raw = util.preprocess_tweet(df_raw['text'][:num_of_tweets])\n",
    "tweet_raw_ = util.preprocess_tweet(df_raw['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_raw=[]\n",
    "for idx,row in df_raw.iterrows():\n",
    "    if row['label'] == 'neutral':\n",
    "        tweet_raw.append(tweet_raw_[idx]+['neutral_corpus'])\n",
    "    elif row['label'] == 'positive':\n",
    "        tweet_raw.append(tweet_raw_[idx]+['positive_corpus'])\n",
    "    else:\n",
    "        tweet_raw.append(tweet_raw_[idx]+['negative_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweets are **************************************** 49826\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the number of tweets are ****************************************',len(tweet_raw))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 tweets after preprocessing********************************\n",
      "[['won', 'the', 'match', 'getin', '', 'plus', 'tomorrow', 'is', 'a', 'very', 'busy', 'day', 'with', 'awareness', \"day's\", 'and', 'debates', 'gulp', 'debates', 'neutral_corpus'], ['some', 'areas', 'of', 'new', 'england', 'could', 'see', 'the', 'first', 'flakes', 'of', 'the', 'season', 'tuesday', 'neutral_corpus'], ['2nd', 'worst', 'qb', 'definitely', 'tony', 'romo', 'the', 'man', 'who', 'likes', 'to', 'share', 'the', 'ball', 'with', 'everyone', 'including', 'the', 'other', 'team', 'negative_corpus'], ['thailand', 'washington', '', 'us', 'president', 'barack', 'obama', 'vowed', 'wednesday', 'as', 'he', 'visited', 'storm-ravaged', 'new', 'jersey', 'shore', 'to', 'neutral_corpus'], ['did', \"y'all\", 'hear', 'what', 'tony', 'romo', 'dressed', 'up', 'as', 'for', 'halloween', 'a', 'giants', 'quaterback', 'cause', \"that's\", 'all', 'he', 'could', 'throw', 'to', 'sunday', 'night', 'neutral_corpus']]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('first 5 tweets after preprocessing********************************')\n",
    "print(tweet_raw[:5])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the frequency of each term, remove the rare terms and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words are****************************************************\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'ma', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'the', 'rt', '&amp', 'a', '', 'amp']\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "punctuation = list(util.string.punctuation)\n",
    "stop = util.stopwords.words('english') + punctuation + ['the','rt','&amp','a','','amp']\n",
    "print('stop words are****************************************************')\n",
    "print(stop)\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## count all terms frequency before removing stop words etc.\n",
    "count_before_remove = util.word_counter(tweet_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 frequency words before removing*****************************\n",
      "[('the', 41256), ('to', 22876), ('neutral_corpus', 22333), ('positive_corpus', 19726), ('', 18639), ('in', 14827), ('on', 14264), ('a', 14081), ('i', 13869), ('and', 13777), ('of', 11858), ('for', 10831), ('is', 10606), ('you', 8904), ('with', 8258), ('be', 7994), ('tomorrow', 7792), ('negative_corpus', 7767), ('at', 7647), ('it', 7392)]\n",
      "**********************************************\n",
      "size of vocabulary before removing is ****************************** 53355\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('top 20 frequency words before removing*****************************')\n",
    "print(count_before_remove.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print(\"size of vocabulary before removing is ******************************\",len(count_before_remove))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_final = util.remove_rare_stop_words(tweet_raw,count_before_remove,rare_term,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 tweets after removing rare term and stop words**************\n",
      "[['match', 'plus', 'tomorrow', 'busy', 'day', 'awareness', \"day's\", 'neutral_corpus'], ['areas', 'new', 'england', 'could', 'see', 'first', 'season', 'tuesday', 'neutral_corpus'], ['2nd', 'worst', 'qb', 'definitely', 'tony', 'romo', 'man', 'likes', 'share', 'ball', 'everyone', 'including', 'team', 'negative_corpus'], ['washington', 'us', 'president', 'barack', 'obama', 'wednesday', 'visited', 'new', 'jersey', 'shore', 'neutral_corpus'], [\"y'all\", 'hear', 'tony', 'romo', 'dressed', 'halloween', 'giants', 'cause', \"that's\", 'could', 'throw', 'sunday', 'night', 'neutral_corpus']]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('first 5 tweets after removing rare term and stop words**************')\n",
    "print(tweet_final[:5])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count all terms frequency after removing stop words etc.\n",
    "counter_uni = util.word_counter(tweet_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 frequency words after removing*******************************\n",
      "[('neutral_corpus', 22333), ('positive_corpus', 19726), ('tomorrow', 7792), ('negative_corpus', 7767), ('may', 7354), ('day', 4182), ('going', 3293), ('night', 3134), ('see', 3081), (\"i'm\", 3035), ('friday', 2949), ('1st', 2845), ('sunday', 2761), ('like', 2722), ('time', 2576), ('get', 2464), (\"it's\", 2446), ('saturday', 2218), ('go', 2125), ('one', 2123)]\n",
      "**********************************************\n",
      "size of vocabulary after removing is 6034\n"
     ]
    }
   ],
   "source": [
    "print('top 20 frequency words after removing*******************************')\n",
    "print(counter_uni.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print(\"size of vocabulary after removing is\",len(counter_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ever', 'justin', 'back', 'game', 'way', 'wednesday', 'jason', 'day', 'national', 'new', 'right', 'going', 'thursday', 'could', 'paul', 'august', 'gonna', 'night', 'video', 'play', 'win', 'sun', '2nd', 'well', 'think', 'since', 'super', 'work', 'know', 'still', 'may', 'set', 'morning', 'world', 'sox', \"i've\", 'brother', 'want', 'sunday', 'next', 'saturday', 'even', '4th', '2', 'good', 'got', 'say', 'go', 'time', 'nicki', \"you're\", '10th', 'like', 'life', 'vs', 'need', 'west', '10', 'coming', 'monday', 'watch', 'every', 'september', 'another', 'god', 'march', 'milan', 'first', \"i'm\", 'cena', 'sat', 'red', 'sharknado', 'man', 'best', 'friday', 'two', 'tomorrow', 'see', 'would', '5', 'already', 'read', 'us', 'weekend', 'season', '1st', 'star', 'getting']\n"
     ]
    }
   ],
   "source": [
    "tweet_final = util.remove_high_frequency_words(tweet_final,counter_uni,['positive_corpus','negative_corpus','neutral_corpus'],(1e-3)/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter_uni = util.word_counter(tweet_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 frequency words after removing*******************************\n",
      "[('neutral_corpus', 22333), ('positive_corpus', 19726), ('negative_corpus', 7767), ('get', 2464), (\"it's\", 2446), ('one', 2123), ('3rd', 1627), ('today', 1620), ('tonight', 1466), ('last', 1444), (\"don't\", 1435), ('make', 1389), ('love', 1264), ('come', 1258), (\"can't\", 1125), ('show', 1078), ('david', 1052), ('big', 1002), ('3', 994), ('happy', 987)]\n",
      "**********************************************\n",
      "size of vocabulary after removing is 5945\n"
     ]
    }
   ],
   "source": [
    "print('top 20 frequency words after removing*******************************')\n",
    "print(counter_uni.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print(\"size of vocabulary after removing is\",len(counter_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the co-occurrence of any two tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_collocation = util.collocation_counter(tweet_final,pmi_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 20 freqency collocation bigrams are **********************\n",
      "[((\"it's\", 'positive_corpus'), 1107), (('get', 'neutral_corpus'), 1052), (('love', 'positive_corpus'), 1038), (('get', 'positive_corpus'), 1009), (('one', 'positive_corpus'), 927), ((\"it's\", 'neutral_corpus'), 920), (('happy', 'positive_corpus'), 886), (('one', 'neutral_corpus'), 870), (('today', 'positive_corpus'), 804), (('3rd', 'neutral_corpus'), 778), (('tonight', 'positive_corpus'), 777), (('great', 'positive_corpus'), 756), (('last', 'neutral_corpus'), 648), (('come', 'positive_corpus'), 642), ((\"can't\", 'positive_corpus'), 635), (('wait', 'positive_corpus'), 632), (('last', 'positive_corpus'), 593), (('today', 'neutral_corpus'), 589), (('make', 'neutral_corpus'), 588), (('make', 'positive_corpus'), 579)]\n",
      "**********************************************\n",
      "size of bi-gram counter is  859930\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the top 20 freqency collocation bigrams are **********************')\n",
    "print(count_collocation.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print('size of bi-gram counter is ',len(count_collocation))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove the low frequency bigrams\n",
    "counter_col = util.remove_rare_term(count_collocation,rare_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of bi-gram counter after removing rare bigrame is  37201\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('size of bi-gram counter after removing rare bigrame is ',len(counter_col))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_x = sorted(counter_col.items(), key=util.operator.itemgetter(1))\n",
    "sorted_x.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 10 colloation words are*********************************\n",
      "[((\"it's\", 'positive_corpus'), 1107), (('get', 'neutral_corpus'), 1052), (('love', 'positive_corpus'), 1038), (('get', 'positive_corpus'), 1009), (('one', 'positive_corpus'), 927), ((\"it's\", 'neutral_corpus'), 920), (('happy', 'positive_corpus'), 886), (('one', 'neutral_corpus'), 870), (('today', 'positive_corpus'), 804), (('3rd', 'neutral_corpus'), 778)]\n",
      "**********************************************\n",
      "the most low 10 colloation r words are*********************************\n",
      "[(('yeah', 'guy'), 6), (('south', 'carolina'), 6), ((\"it's\", 'safe'), 6), (('done', 'something'), 6), (('poland', 'positive_corpus'), 6), (('mikasa', 'neutral_corpus'), 6), (('search', 'negative_corpus'), 6), (('race', 'racing'), 6), (('gets', 'looks'), 6), (('found', 'news'), 6)]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the top 10 colloation words are*********************************')\n",
    "print(sorted_x[:10])\n",
    "print(\"**********************************************\")\n",
    "\n",
    "sorted_x.reverse()\n",
    "print('the most low 10 colloation r words are*********************************')\n",
    "print(sorted_x[:10])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct word occurrences matrix and PMI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document = [['A', 'B'], ['C', 'B'], ['A', 'B', 'C', 'D']]\n",
    "# counter_uni = util.word_counter(document)\n",
    "# counter_col = util.collocation_counter(document)\n",
    "df_coll,matrix_coll = util.construct_word_occurrence_matrix(counter_uni,counter_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              nirvana  demand  cape  howard  cst  tab  teacher  cougar  \\\n",
      "nirvana          10.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "demand            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "cape              0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "howard            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "cst               0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "tab               0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "teacher           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "cougar            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "ballot            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "looking           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "defeats           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "movie             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "oct               0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "bible             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "hint              0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "potential         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "compare           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "it's             13.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "75                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "superstar         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "polling           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "pageant           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "teaser            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "creepy            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "lovely            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "announce          0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "programme         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "scheduled         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "denver            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "khan              0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "...               ...     ...   ...     ...  ...  ...      ...     ...   \n",
      "girls             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "likes             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "protected         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "neck              0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "90                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "labour            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "skinny            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "cyrus             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "santa             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "shoes             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "lloyd             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "cleaning          0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "stevie            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "plate             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "registration      0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "dr                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "attempt           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "bruce             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "professor         0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "audience          0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "21                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "44                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "wanting           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "web               0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "ac                0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "ideal             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "casual            0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "form              0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "money             0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "rickman           0.0     0.0   0.0     0.0  0.0  0.0      0.0     0.0   \n",
      "\n",
      "              ballot  looking   ...      21   44  wanting  web   ac  ideal  \\\n",
      "nirvana          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "demand           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "cape             0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "howard           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "cst              0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "tab              0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "teacher          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "cougar           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "ballot           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "looking          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "defeats          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "movie            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "oct              0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "bible            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "hint             0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "potential        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "compare          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "it's             0.0     15.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "75               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "superstar        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "polling          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "pageant          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "teaser           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "creepy           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "lovely           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "announce         0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "programme        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "scheduled        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "denver           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "khan             0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "...              ...      ...   ...     ...  ...      ...  ...  ...    ...   \n",
      "girls            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "likes            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "protected        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "neck             0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "90               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "labour           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "skinny           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "cyrus            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "santa            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "shoes            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "lloyd            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "cleaning         0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "stevie           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "plate            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "registration     0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "dr               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "attempt          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "bruce            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "professor        0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "audience         0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "21               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "44               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "wanting          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "web              0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "ac               0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "ideal            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "casual           0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "form             0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "money            0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "rickman          0.0      0.0   ...     0.0  0.0      0.0  0.0  0.0    0.0   \n",
      "\n",
      "              casual  form  money  rickman  \n",
      "nirvana          0.0   0.0    0.0      0.0  \n",
      "demand           0.0   0.0    0.0      0.0  \n",
      "cape             0.0   0.0    0.0      0.0  \n",
      "howard           0.0   0.0    0.0      0.0  \n",
      "cst              0.0   0.0    0.0      0.0  \n",
      "tab              0.0   0.0    0.0      0.0  \n",
      "teacher          0.0   0.0    0.0      0.0  \n",
      "cougar           0.0   0.0    0.0      0.0  \n",
      "ballot           0.0   0.0    0.0      0.0  \n",
      "looking          0.0   0.0    0.0      0.0  \n",
      "defeats          0.0   0.0    0.0      0.0  \n",
      "movie            0.0   0.0    0.0      0.0  \n",
      "oct              0.0   0.0    0.0      0.0  \n",
      "bible            0.0   0.0    0.0      0.0  \n",
      "hint             0.0   0.0    0.0      0.0  \n",
      "potential        0.0   0.0    0.0      0.0  \n",
      "compare          0.0   0.0    0.0      0.0  \n",
      "it's             0.0   0.0    7.0      0.0  \n",
      "75               0.0   0.0    0.0      0.0  \n",
      "superstar        0.0   0.0    0.0      0.0  \n",
      "polling          0.0   0.0    0.0      0.0  \n",
      "pageant          0.0   0.0    0.0      0.0  \n",
      "teaser           0.0   0.0    0.0      0.0  \n",
      "creepy           0.0   0.0    0.0      0.0  \n",
      "lovely           0.0   0.0    0.0      0.0  \n",
      "announce         0.0   0.0    0.0      0.0  \n",
      "programme        0.0   0.0    0.0      0.0  \n",
      "scheduled        0.0   0.0    0.0      0.0  \n",
      "denver           0.0   0.0    0.0      0.0  \n",
      "khan             0.0   0.0    0.0      0.0  \n",
      "...              ...   ...    ...      ...  \n",
      "girls            0.0   0.0    0.0      0.0  \n",
      "likes            0.0   0.0    0.0      0.0  \n",
      "protected        0.0   0.0    0.0      0.0  \n",
      "neck             0.0   0.0    0.0      0.0  \n",
      "90               0.0   0.0    0.0      0.0  \n",
      "labour           0.0   0.0    0.0      0.0  \n",
      "skinny           0.0   0.0    0.0      0.0  \n",
      "cyrus            0.0   0.0    0.0      0.0  \n",
      "santa            0.0   0.0    0.0      0.0  \n",
      "shoes            0.0   0.0    0.0      0.0  \n",
      "lloyd            0.0   0.0    0.0      0.0  \n",
      "cleaning         0.0   0.0    0.0      0.0  \n",
      "stevie           0.0   0.0    0.0      0.0  \n",
      "plate            0.0   0.0    0.0      0.0  \n",
      "registration     0.0   0.0    0.0      0.0  \n",
      "dr               0.0   0.0    0.0      0.0  \n",
      "attempt          0.0  10.0    0.0      0.0  \n",
      "bruce            0.0   0.0    0.0      0.0  \n",
      "professor        0.0   0.0    0.0      0.0  \n",
      "audience         0.0   0.0    0.0      0.0  \n",
      "21               0.0   0.0    0.0      0.0  \n",
      "44               0.0   0.0    0.0      0.0  \n",
      "wanting          0.0   0.0    0.0      0.0  \n",
      "web              0.0   0.0    0.0      0.0  \n",
      "ac               0.0   0.0    0.0      0.0  \n",
      "ideal            0.0   0.0    0.0      0.0  \n",
      "casual           0.0   0.0    0.0      0.0  \n",
      "form             0.0   0.0    0.0      0.0  \n",
      "money            0.0   0.0    0.0      0.0  \n",
      "rickman          0.0   0.0    0.0      0.0  \n",
      "\n",
      "[5945 rows x 5945 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_index = df_coll.index.tolist()\n",
    "names_header = df_coll.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying laplace smoothed, parameter is 1\n"
     ]
    }
   ],
   "source": [
    "dff_pmi,ppmi_matrix = util.PPMI_matrix(names_index,names_header,matrix_coll,la_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               nirvana    demand      cape    howard       cst       tab  \\\n",
      "nirvana       3.228089  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "demand        0.000000  0.042609  0.026492  0.006536  0.044545  0.035370   \n",
      "cape          0.000000  0.026492  0.010375  0.000000  0.028428  0.019253   \n",
      "howard        0.000000  0.006536  0.000000  0.000000  0.008473  0.000000   \n",
      "cst           0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "tab           0.000000  0.035370  0.019253  0.000000  0.037306  0.028131   \n",
      "teacher       0.000000  0.029605  0.013488  0.000000  0.031541  0.022366   \n",
      "cougar        0.000000  0.042850  0.026733  0.006778  0.044787  0.035612   \n",
      "ballot        0.000000  0.045030  0.028913  0.008957  0.046966  0.037791   \n",
      "looking       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "defeats       0.000000  0.045030  0.028913  0.008957  0.046966  0.037791   \n",
      "movie         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "oct           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "bible         0.000000  0.037297  0.021180  0.001224  0.039233  0.030058   \n",
      "hint          0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "potential     0.000000  0.041158  0.025041  0.005086  0.043094  0.033919   \n",
      "compare       0.000000  0.043576  0.027459  0.007504  0.045513  0.036338   \n",
      "it's          1.951200  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "75            0.000000  0.041883  0.025766  0.005811  0.043820  0.034644   \n",
      "superstar     0.000000  0.043576  0.027459  0.007504  0.045513  0.036338   \n",
      "polling       0.000000  0.045272  0.029155  0.009200  0.047208  0.038033   \n",
      "pageant       0.000000  0.007953  0.000000  0.000000  0.009889  0.000714   \n",
      "teaser        0.000000  0.045514  0.029397  0.009442  0.047451  0.038275   \n",
      "creepy        0.000000  0.047212  0.031095  0.011140  0.049148  0.039973   \n",
      "lovely        0.000000  0.014343  0.000000  0.000000  0.016279  0.007104   \n",
      "announce      0.000000  0.025774  0.009657  0.000000  0.027711  0.018535   \n",
      "programme     0.000000  0.044061  0.027944  0.007988  0.045997  0.036822   \n",
      "scheduled     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "denver        0.000000  0.034648  0.018531  0.000000  0.036584  0.027409   \n",
      "khan          0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "...                ...       ...       ...       ...       ...       ...   \n",
      "girls         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "likes         0.000000  0.038502  0.022385  0.002430  0.040439  0.031263   \n",
      "protected     0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "neck          0.000000  0.045757  0.029640  0.009684  0.047693  0.038518   \n",
      "90            0.000000  0.044787  0.028670  0.008715  0.046724  0.037548   \n",
      "labour        0.000000  0.008898  0.000000  0.000000  0.010834  0.001659   \n",
      "skinny        0.000000  0.047212  0.031095  0.011140  0.049148  0.039973   \n",
      "cyrus         0.000000  0.035370  0.019253  0.000000  0.037306  0.028131   \n",
      "santa         0.000000  0.041400  0.025283  0.005327  0.043336  0.034161   \n",
      "shoes         0.000000  0.042850  0.026733  0.006778  0.044787  0.035612   \n",
      "lloyd         0.000000  0.030564  0.014447  0.000000  0.032500  0.023325   \n",
      "cleaning      0.000000  0.045030  0.028913  0.008957  0.046966  0.037791   \n",
      "stevie        0.000000  0.042367  0.026250  0.006294  0.044303  0.035128   \n",
      "plate         0.000000  0.040916  0.024799  0.004844  0.042853  0.033677   \n",
      "registration  0.000000  0.045030  0.028913  0.008957  0.046966  0.037791   \n",
      "dr            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "attempt       0.000000  0.017192  0.001075  0.000000  0.019129  0.009953   \n",
      "bruce         0.000000  0.022192  0.006075  0.000000  0.024129  0.014953   \n",
      "professor     0.000000  0.043819  0.027702  0.007746  0.045755  0.036580   \n",
      "audience      0.000000  0.040675  0.024558  0.004602  0.042611  0.033436   \n",
      "21            0.000000  0.011499  0.000000  0.000000  0.013436  0.004260   \n",
      "44            0.000000  0.044061  0.027944  0.007988  0.045997  0.036822   \n",
      "wanting       0.000000  0.043576  0.027459  0.007504  0.045513  0.036338   \n",
      "web           0.000000  0.041400  0.025283  0.005327  0.043336  0.034161   \n",
      "ac            0.000000  0.033686  0.017569  0.000000  0.035622  0.026447   \n",
      "ideal         0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "casual        0.000000  0.045272  0.029155  0.009200  0.047208  0.038033   \n",
      "form          0.000000  0.009134  0.000000  0.000000  0.011070  0.001895   \n",
      "money         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rickman       0.000000  0.044545  0.028428  0.008473  0.046482  0.037306   \n",
      "\n",
      "               teacher    cougar    ballot  looking    ...           21  \\\n",
      "nirvana       0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "demand        0.029605  0.042850  0.045030  0.00000    ...     0.011499   \n",
      "cape          0.013488  0.026733  0.028913  0.00000    ...     0.000000   \n",
      "howard        0.000000  0.006778  0.008957  0.00000    ...     0.000000   \n",
      "cst           0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "tab           0.022366  0.035612  0.037791  0.00000    ...     0.004260   \n",
      "teacher       0.016601  0.029847  0.032026  0.00000    ...     0.000000   \n",
      "cougar        0.029847  0.043092  0.045272  0.00000    ...     0.011741   \n",
      "ballot        0.032026  0.045272  0.047451  0.00000    ...     0.013920   \n",
      "looking       0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "defeats       0.032026  0.045272  0.047451  0.00000    ...     0.013920   \n",
      "movie         0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "oct           0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "bible         0.024293  0.037538  0.039718  0.00000    ...     0.006187   \n",
      "hint          0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "potential     0.028154  0.041400  0.043579  0.00000    ...     0.010049   \n",
      "compare       0.030573  0.043818  0.045998  0.00000    ...     0.012467   \n",
      "it's          0.000000  0.000000  0.000000  2.04563    ...     0.000000   \n",
      "75            0.028879  0.042125  0.044304  0.00000    ...     0.010774   \n",
      "superstar     0.030573  0.043818  0.045998  0.00000    ...     0.012467   \n",
      "polling       0.032268  0.045514  0.047693  0.00000    ...     0.014163   \n",
      "pageant       0.000000  0.008194  0.010374  0.00000    ...     0.000000   \n",
      "teaser        0.032510  0.045756  0.047935  0.00000    ...     0.014405   \n",
      "creepy        0.034208  0.047454  0.049633  0.00000    ...     0.016103   \n",
      "lovely        0.001339  0.014585  0.016764  0.00000    ...     0.000000   \n",
      "announce      0.012770  0.026016  0.028195  0.00000    ...     0.000000   \n",
      "programme     0.031057  0.044303  0.046482  0.00000    ...     0.012951   \n",
      "scheduled     0.000000  0.000000  0.000020  0.00000    ...     0.000000   \n",
      "denver        0.021644  0.034890  0.037069  0.00000    ...     0.003539   \n",
      "khan          0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "...                ...       ...       ...      ...    ...          ...   \n",
      "girls         0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "likes         0.025498  0.038744  0.040923  0.00000    ...     0.007393   \n",
      "protected     0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "neck          0.032753  0.045999  0.048178  0.00000    ...     0.014647   \n",
      "90            0.031783  0.045029  0.047208  0.00000    ...     0.013678   \n",
      "labour        0.000000  0.009139  0.011319  0.00000    ...     0.000000   \n",
      "skinny        0.034208  0.047454  0.049633  0.00000    ...     0.016103   \n",
      "cyrus         0.022366  0.035612  0.037791  0.00000    ...     0.004260   \n",
      "santa         0.028396  0.041641  0.043821  0.00000    ...     0.010290   \n",
      "shoes         0.029847  0.043092  0.045272  0.00000    ...     0.011741   \n",
      "lloyd         0.017560  0.030806  0.032985  0.00000    ...     0.000000   \n",
      "cleaning      0.032026  0.045272  0.047451  0.00000    ...     0.013920   \n",
      "stevie        0.029363  0.042609  0.044788  0.00000    ...     0.011257   \n",
      "plate         0.027912  0.041158  0.043337  0.00000    ...     0.009807   \n",
      "registration  0.032026  0.045272  0.047451  0.00000    ...     0.013920   \n",
      "dr            0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "attempt       0.004188  0.017434  0.019613  0.00000    ...     0.000000   \n",
      "bruce         0.009188  0.022434  0.024613  0.00000    ...     0.000000   \n",
      "professor     0.030815  0.044060  0.046240  0.00000    ...     0.012709   \n",
      "audience      0.027671  0.040917  0.043096  0.00000    ...     0.009565   \n",
      "21            0.000000  0.011741  0.013920  0.00000    ...     0.000000   \n",
      "44            0.031057  0.044303  0.046482  0.00000    ...     0.012951   \n",
      "wanting       0.030573  0.043818  0.045998  0.00000    ...     0.012467   \n",
      "web           0.028396  0.041641  0.043821  0.00000    ...     0.010290   \n",
      "ac            0.020682  0.033928  0.036107  0.00000    ...     0.002577   \n",
      "ideal         0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "casual        0.032268  0.045514  0.047693  0.00000    ...     0.014163   \n",
      "form          0.000000  0.009376  0.011555  0.00000    ...     0.000000   \n",
      "money         0.000000  0.000000  0.000000  0.00000    ...     0.000000   \n",
      "rickman       0.031541  0.044787  0.046966  0.00000    ...     0.013436   \n",
      "\n",
      "                    44   wanting       web        ac     ideal    casual  \\\n",
      "nirvana       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "demand        0.044061  0.043576  0.041400  0.033686  0.044545  0.045272   \n",
      "cape          0.027944  0.027459  0.025283  0.017569  0.028428  0.029155   \n",
      "howard        0.007988  0.007504  0.005327  0.000000  0.008473  0.009200   \n",
      "cst           0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "tab           0.036822  0.036338  0.034161  0.026447  0.037306  0.038033   \n",
      "teacher       0.031057  0.030573  0.028396  0.020682  0.031541  0.032268   \n",
      "cougar        0.044303  0.043818  0.041641  0.033928  0.044787  0.045514   \n",
      "ballot        0.046482  0.045998  0.043821  0.036107  0.046966  0.047693   \n",
      "looking       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "defeats       0.046482  0.045998  0.043821  0.036107  0.046966  0.047693   \n",
      "movie         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "oct           0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "bible         0.038749  0.038264  0.036088  0.028374  0.039233  0.039960   \n",
      "hint          0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "potential     0.042610  0.042126  0.039949  0.032235  0.043094  0.043821   \n",
      "compare       0.045029  0.044544  0.042367  0.034654  0.045513  0.046240   \n",
      "it's          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "75            0.043335  0.042851  0.040674  0.032960  0.043820  0.044546   \n",
      "superstar     0.045029  0.044544  0.042367  0.034654  0.045513  0.046240   \n",
      "polling       0.046724  0.046240  0.044063  0.036349  0.047208  0.047935   \n",
      "pageant       0.009405  0.008920  0.006744  0.000000  0.009889  0.010616   \n",
      "teaser        0.046966  0.046482  0.044305  0.036592  0.047451  0.048178   \n",
      "creepy        0.048664  0.048180  0.046003  0.038289  0.049148  0.049875   \n",
      "lovely        0.015795  0.015311  0.013134  0.005420  0.016279  0.017006   \n",
      "announce      0.027226  0.026742  0.024565  0.016851  0.027711  0.028437   \n",
      "programme     0.045513  0.045029  0.042852  0.035138  0.045997  0.046724   \n",
      "scheduled     0.000000  0.000000  0.000000  0.000000  0.000000  0.000262   \n",
      "denver        0.036100  0.035616  0.033439  0.025725  0.036584  0.037311   \n",
      "khan          0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "...                ...       ...       ...       ...       ...       ...   \n",
      "girls         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "likes         0.039954  0.039470  0.037293  0.029579  0.040439  0.041165   \n",
      "protected     0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "neck          0.047209  0.046725  0.044548  0.036834  0.047693  0.048420   \n",
      "90            0.046239  0.045755  0.043578  0.035865  0.046724  0.047451   \n",
      "labour        0.010350  0.009865  0.007689  0.000000  0.010834  0.011561   \n",
      "skinny        0.048664  0.048180  0.046003  0.038289  0.049148  0.049875   \n",
      "cyrus         0.036822  0.036338  0.034161  0.026447  0.037306  0.038033   \n",
      "santa         0.042852  0.042367  0.040191  0.032477  0.043336  0.044063   \n",
      "shoes         0.044303  0.043818  0.041641  0.033928  0.044787  0.045514   \n",
      "lloyd         0.032016  0.031532  0.029355  0.021641  0.032500  0.033227   \n",
      "cleaning      0.046482  0.045998  0.043821  0.036107  0.046966  0.047693   \n",
      "stevie        0.043819  0.043335  0.041158  0.033444  0.044303  0.045030   \n",
      "plate         0.042368  0.041884  0.039707  0.031994  0.042853  0.043580   \n",
      "registration  0.046482  0.045998  0.043821  0.036107  0.046966  0.047693   \n",
      "dr            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "attempt       0.018644  0.018160  0.015983  0.008270  0.019129  0.019856   \n",
      "bruce         0.023644  0.023160  0.020983  0.013269  0.024129  0.024856   \n",
      "professor     0.045271  0.044786  0.042610  0.034896  0.045755  0.046482   \n",
      "audience      0.042127  0.041643  0.039466  0.031752  0.042611  0.043338   \n",
      "21            0.012951  0.012467  0.010290  0.002577  0.013436  0.014163   \n",
      "44            0.045513  0.045029  0.042852  0.035138  0.045997  0.046724   \n",
      "wanting       0.045029  0.044544  0.042367  0.034654  0.045513  0.046240   \n",
      "web           0.042852  0.042367  0.040191  0.032477  0.043336  0.044063   \n",
      "ac            0.035138  0.034654  0.032477  0.024763  0.035622  0.036349   \n",
      "ideal         0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "casual        0.046724  0.046240  0.044063  0.036349  0.047208  0.047935   \n",
      "form          0.010586  0.010102  0.007925  0.000211  0.011070  0.011797   \n",
      "money         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "rickman       0.045997  0.045513  0.043336  0.035622  0.046482  0.047208   \n",
      "\n",
      "                  form     money   rickman  \n",
      "nirvana       0.000000  0.000000  0.000000  \n",
      "demand        0.009134  0.000000  0.044545  \n",
      "cape          0.000000  0.000000  0.028428  \n",
      "howard        0.000000  0.000000  0.008473  \n",
      "cst           0.011070  0.000000  0.046482  \n",
      "tab           0.001895  0.000000  0.037306  \n",
      "teacher       0.000000  0.000000  0.031541  \n",
      "cougar        0.009376  0.000000  0.044787  \n",
      "ballot        0.011555  0.000000  0.046966  \n",
      "looking       0.000000  0.000000  0.000000  \n",
      "defeats       0.011555  0.000000  0.046966  \n",
      "movie         0.000000  0.000000  0.000000  \n",
      "oct           0.000000  0.000000  0.000000  \n",
      "bible         0.003822  0.000000  0.039233  \n",
      "hint          0.011070  0.000000  0.046482  \n",
      "potential     0.007683  0.000000  0.043094  \n",
      "compare       0.010102  0.000000  0.045513  \n",
      "it's          0.000000  1.185129  0.000000  \n",
      "75            0.008408  0.000000  0.043820  \n",
      "superstar     0.010102  0.000000  0.045513  \n",
      "polling       0.011797  0.000000  0.047208  \n",
      "pageant       0.000000  0.000000  0.009889  \n",
      "teaser        0.012040  0.000000  0.047451  \n",
      "creepy        0.013737  0.000000  0.049148  \n",
      "lovely        0.000000  0.000000  0.016279  \n",
      "announce      0.000000  0.000000  0.027711  \n",
      "programme     0.010586  0.000000  0.045997  \n",
      "scheduled     0.000000  0.000000  0.000000  \n",
      "denver        0.001173  0.000000  0.036584  \n",
      "khan          0.011070  0.000000  0.046482  \n",
      "...                ...       ...       ...  \n",
      "girls         0.000000  0.000000  0.000000  \n",
      "likes         0.005027  0.000000  0.040439  \n",
      "protected     0.011070  0.000000  0.046482  \n",
      "neck          0.012282  0.000000  0.047693  \n",
      "90            0.011313  0.000000  0.046724  \n",
      "labour        0.000000  0.000000  0.010834  \n",
      "skinny        0.013737  0.000000  0.049148  \n",
      "cyrus         0.001895  0.000000  0.037306  \n",
      "santa         0.007925  0.000000  0.043336  \n",
      "shoes         0.009376  0.000000  0.044787  \n",
      "lloyd         0.000000  0.000000  0.032500  \n",
      "cleaning      0.011555  0.000000  0.046966  \n",
      "stevie        0.008892  0.000000  0.044303  \n",
      "plate         0.007442  0.000000  0.042853  \n",
      "registration  0.011555  0.000000  0.046966  \n",
      "dr            0.000000  0.000000  0.000000  \n",
      "attempt       3.443149  0.000000  0.019129  \n",
      "bruce         0.000000  0.000000  0.024129  \n",
      "professor     0.010344  0.000000  0.045755  \n",
      "audience      0.007200  0.000000  0.042611  \n",
      "21            0.000000  0.000000  0.013436  \n",
      "44            0.010586  0.000000  0.045997  \n",
      "wanting       0.010102  0.000000  0.045513  \n",
      "web           0.007925  0.000000  0.043336  \n",
      "ac            0.000211  0.000000  0.035622  \n",
      "ideal         0.011070  0.000000  0.046482  \n",
      "casual        0.011797  0.000000  0.047208  \n",
      "form          0.000000  0.000000  0.011070  \n",
      "money         0.000000  0.000000  0.000000  \n",
      "rickman       0.011070  0.000000  0.046482  \n",
      "\n",
      "[5945 rows x 5945 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dff_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest PPMI value tuples is****************************\n",
      "('fighters', 'foo')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('the highest PPMI value tuples is****************************')\n",
    "print(dff_pmi.stack().index[util.np.argmax(ppmi_matrix)])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply symmetrics SVD to get the word and context embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W,C = util.construct_word_embedding(dimension,ppmi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.38012281  0.0250975   0.32396115 ...  0.06085082 -0.22318987\n",
      "   0.00787766]\n",
      " [-0.01073546 -0.20584741 -0.00232953 ...  0.00118904  0.00048279\n",
      "  -0.00088854]\n",
      " [-0.01961335 -0.13279468 -0.02828063 ...  0.00155697  0.02578281\n",
      "  -0.1479699 ]\n",
      " ...\n",
      " [-0.02943224 -0.04553242 -0.00059477 ... -0.02400322 -0.0360831\n",
      "  -0.0707499 ]\n",
      " [-0.29689284  0.00850647  0.27530284 ...  0.03548187  0.06587862\n",
      "   0.05768785]\n",
      " [-0.0116884  -0.21934881 -0.00228434 ...  0.00311485  0.0014654\n",
      "  -0.00528072]]\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W is**********************************************\n",
      "(5945, 100)\n",
      "**********************************************\n",
      "shape of C is*********************************************\n",
      "(5945, 100)\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('shape of W is**********************************************')\n",
    "print(W.shape)\n",
    "print(\"**********************************************\")\n",
    "\n",
    "print('shape of C is*********************************************')\n",
    "print(C.shape)\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame3 = frame2.div(frame2.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export word embedding to csv file!!!\n"
     ]
    }
   ],
   "source": [
    "header = dff_pmi.index.tolist()\n",
    "frame=util.to_csv(W,header,'test_svd_embedding.csv')\n",
    "print('export word embedding to csv file!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame2 = frame.div(frame.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.iloc[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_corpus\n",
      "it's\n",
      "neutral_corpus\n",
      "get\n",
      "one\n",
      "last\n",
      "negative_corpus\n",
      "come\n",
      "great\n",
      "3rd\n",
      "don't\n",
      "can't\n",
      "3\n",
      "really\n",
      "show\n",
      "wait\n",
      "hope\n",
      "concert\n",
      "live\n",
      "music\n",
      "big\n",
      "better\n",
      "tuesday\n",
      "free\n",
      "4\n",
      "october\n",
      "lol\n",
      "seeing\n",
      "much\n",
      "he's\n",
      "july\n",
      "tickets\n",
      "u\n",
      "playing\n",
      "pi\n",
      "amazing\n",
      "david\n",
      "awakens\n",
      "home\n",
      "please\n",
      "november\n",
      "sept\n",
      "meet\n",
      "little\n",
      "join\n",
      "look\n",
      "guys\n",
      "band\n",
      "december\n",
      "shirt\n",
      "school\n",
      "looking\n",
      "team\n",
      "fleetwood\n",
      "tribute\n",
      "thing\n",
      "miss\n",
      "starwars\n",
      "wild\n",
      "thriller\n",
      "black\n",
      "top\n",
      "2015\n",
      "vancouver\n",
      "bad\n",
      "merry\n",
      "wanna\n",
      "anyone\n",
      "find\n",
      "im\n",
      "pll\n",
      "sonic\n",
      "tyler\n",
      "horror\n",
      "grade\n",
      "cheese\n",
      "made\n",
      "remember\n",
      "kind\n",
      "test\n",
      "proud\n",
      "easter\n",
      "listen\n",
      "cara\n",
      "real\n",
      "painter\n",
      "cinema\n",
      "books\n",
      "clarke\n",
      "answer\n",
      "cd\n",
      "jackson's\n",
      "bloody\n",
      "polish\n",
      "diego\n",
      "seen\n",
      "wichita\n",
      "championship\n",
      "stores\n",
      "john\n"
     ]
    }
   ],
   "source": [
    "most_similar = util.show_most_similar('positive_corpus',frame2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame1 = frame.reset_index(drop=False)\n",
    "\n",
    "label = []\n",
    "for i in most_similar:\n",
    "    label.append(frame1.iloc[i]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative_corpus', 'neutral_corpus', \"it's\", 'get', 'one', 'positive_corpus', \"don't\", 'people', 'said', \"he's\", 'make', 'isis', 'eu', 'really', 'today', 'says', 'iraq', \"that's\", '3rd', 'last', 'u', \"can't\", 'lol', 'tories', 'elections', 'agreement', 'babies', 'shit', 'look', 'trump', 'mumbai', 'take', 'watching', 'chancellor', 'islam', 'sentence', 'horror', 'petition', 'yemen', 'coalition', 'german', 'islamic', 'fears', \"blair's\", 'ellen', 'muslims', 'spread', 'fatal', 'protect', \"jenner's\", 'wild', 'immigrants', 'santorum', 'village', 'women', 'staff', 'defeat', 'news', 'kurds', 'sect', 'bruce', 'buhari', 'better', 'soldiers', 'crash', 'im', 'yakub', 'hindus', 'sure', 'justice', 'borno', 'pray', 'troops', 'bad', 'controls', 'attack', 'mercy', \"arabia's\", \"perry's\", 'charge', 'accident', 'give', 'danny', \"doesn't\", 'nigerian', 'face', 'jews', 'much', 'army', 'love', 'sc', 'never', 'religious', 'pregnant', 'turkish', 'blasts', 'muslim', 'france', 'jail', 'december']\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6547160609181961"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1.loc[0][1:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
