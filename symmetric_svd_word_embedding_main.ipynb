{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symmetric_svd_word_embedding_utilities as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether consider the order of pmi\n",
    "pmi_order = False\n",
    "\n",
    "# threshold of rare unigram\n",
    "rare_term = 10\n",
    "\n",
    "# threshold of rare bigram\n",
    "rare_bigram = 5\n",
    "\n",
    "# dimension of matrix generated\n",
    "dimension = 100\n",
    "\n",
    "# value applied in laplace smooth\n",
    "la_smooth = 1\n",
    "\n",
    "# number of tweets deal with\n",
    "num_of_tweets = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = './train_tweets'\n",
    "header_row = ['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the filenames are ***************************\n",
      "['tweets_senEval.txt']\n",
      "Original size of data is  49828\n",
      "after remove duplicate, the size is  49826\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw = util.read_from_txt(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mypath = '../tweets_set_ire'\n",
    "# header_row = ['ID', 'ID_STR', 'author', 'text', 'time', 'location', 'latitude', 'longitude', 'screen_place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = util.read_from_csv(mypath,header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first row is*******************************\n",
      "text     Won the match #getin . Plus tomorrow is a very...\n",
      "label                                              neutral\n",
      "Name: 0, dtype: object\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the first row is*******************************')\n",
    "print(df_raw.iloc[0])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing tweet, remove mention, urls, emoji, strip each token and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_raw = util.preprocess_tweet(df_raw['text'][:num_of_tweets])\n",
    "tweet_raw_ = util.preprocess_tweet(df_raw['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_raw=[]\n",
    "for idx,row in df_raw.iterrows():\n",
    "    if row['label'] == 'neutral':\n",
    "        tweet_raw.append(tweet_raw_[idx]+['neutral_corpus'])\n",
    "    elif row['label'] == 'positive':\n",
    "        tweet_raw.append(tweet_raw_[idx]+['positive_corpus'])\n",
    "    else:\n",
    "        tweet_raw.append(tweet_raw_[idx]+['negative_corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of tweets are **************************************** 49826\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the number of tweets are ****************************************',len(tweet_raw))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 tweets after preprocessing********************************\n",
      "[['won', 'the', 'match', 'getin', '', 'plus', 'tomorrow', 'is', 'a', 'very', 'busy', 'day', 'with', 'awareness', \"day's\", 'and', 'debates', 'gulp', 'debates', 'neutral_corpus'], ['some', 'areas', 'of', 'new', 'england', 'could', 'see', 'the', 'first', 'flakes', 'of', 'the', 'season', 'tuesday', 'neutral_corpus'], ['2nd', 'worst', 'qb', 'definitely', 'tony', 'romo', 'the', 'man', 'who', 'likes', 'to', 'share', 'the', 'ball', 'with', 'everyone', 'including', 'the', 'other', 'team', 'negative_corpus'], ['thailand', 'washington', '', 'us', 'president', 'barack', 'obama', 'vowed', 'wednesday', 'as', 'he', 'visited', 'storm-ravaged', 'new', 'jersey', 'shore', 'to', 'neutral_corpus'], ['did', \"y'all\", 'hear', 'what', 'tony', 'romo', 'dressed', 'up', 'as', 'for', 'halloween', 'a', 'giants', 'quaterback', 'cause', \"that's\", 'all', 'he', 'could', 'throw', 'to', 'sunday', 'night', 'neutral_corpus']]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('first 5 tweets after preprocessing********************************')\n",
    "print(tweet_raw[:5])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the frequency of each term, remove the rare terms and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words are****************************************************\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', 'the', 'rt', '&amp', 'a', '', 'amp']\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "punctuation = list(util.string.punctuation)\n",
    "stop = util.stopwords.words('english') + punctuation + ['the','rt','&amp','a','','amp']\n",
    "print('stop words are****************************************************')\n",
    "print(stop)\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count all terms frequency before removing stop words etc.\n",
    "count_before_remove = util.word_counter(tweet_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 frequency words before removing*****************************\n",
      "[('the', 41256), ('to', 22876), ('neutral_corpus', 22333), ('positive_corpus', 19726), ('', 18639), ('in', 14827), ('on', 14264), ('a', 14081), ('i', 13869), ('and', 13777), ('of', 11858), ('for', 10831), ('is', 10606), ('you', 8904), ('with', 8258), ('be', 7994), ('tomorrow', 7792), ('negative_corpus', 7767), ('at', 7647), ('it', 7392)]\n",
      "**********************************************\n",
      "size of vocabulary before removing is ****************************** 53355\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('top 20 frequency words before removing*****************************')\n",
    "print(count_before_remove.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print(\"size of vocabulary before removing is ******************************\",len(count_before_remove))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_final = util.remove_rare_stop_words(tweet_raw,count_before_remove,rare_term,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 tweets after removing rare term and stop words**************\n",
      "[['match', 'plus', 'tomorrow', 'busy', 'day', 'awareness', \"day's\", 'neutral_corpus'], ['areas', 'new', 'england', 'could', 'see', 'first', 'season', 'tuesday', 'neutral_corpus'], ['2nd', 'worst', 'qb', 'definitely', 'tony', 'romo', 'man', 'likes', 'share', 'ball', 'everyone', 'including', 'team', 'negative_corpus'], ['washington', 'us', 'president', 'barack', 'obama', 'wednesday', 'visited', 'new', 'jersey', 'shore', 'neutral_corpus'], [\"y'all\", 'hear', 'tony', 'romo', 'dressed', 'halloween', 'giants', 'cause', \"that's\", 'could', 'throw', 'sunday', 'night', 'neutral_corpus']]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('first 5 tweets after removing rare term and stop words**************')\n",
    "print(tweet_final[:5])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all terms frequency after removing stop words etc.\n",
    "counter_uni = util.word_counter(tweet_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 frequency words after removing*******************************\n",
      "[('neutral_corpus', 22333), ('positive_corpus', 19726), ('tomorrow', 7792), ('negative_corpus', 7767), ('may', 7354), ('day', 4182), ('going', 3293), ('night', 3134), ('see', 3081), (\"i'm\", 3035), ('friday', 2949), ('1st', 2845), ('sunday', 2761), ('like', 2722), ('time', 2576), ('get', 2464), ('saturday', 2218), ('go', 2125), ('one', 2123), ('new', 2035)]\n",
      "**********************************************\n",
      "size of vocabulary after removing is 6012\n"
     ]
    }
   ],
   "source": [
    "print('top 20 frequency words after removing*******************************')\n",
    "print(counter_uni.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print(\"size of vocabulary after removing is\",len(counter_uni))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count the co-occurrence of any two tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_collocation = util.collocation_counter(tweet_final,pmi_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 20 freqency collocation bigrams are **********************\n",
      "[(('tomorrow', 'positive_corpus'), 3740), (('may', 'neutral_corpus'), 3180), (('tomorrow', 'neutral_corpus'), 3058), (('may', 'positive_corpus'), 2474), (('day', 'positive_corpus'), 2312), (('see', 'positive_corpus'), 1724), (('may', 'negative_corpus'), 1700), (('night', 'positive_corpus'), 1519), ((\"i'm\", 'positive_corpus'), 1450), (('going', 'neutral_corpus'), 1426), (('going', 'positive_corpus'), 1400), (('day', 'neutral_corpus'), 1388), (('friday', 'positive_corpus'), 1383), (('night', 'neutral_corpus'), 1320), (('good', 'positive_corpus'), 1267), (('friday', 'neutral_corpus'), 1260), (('sunday', 'neutral_corpus'), 1252), (('1st', 'neutral_corpus'), 1244), (('going', 'tomorrow'), 1233), (('sunday', 'positive_corpus'), 1170)]\n",
      "**********************************************\n",
      "size of bi-gram counter is  1057268\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the top 20 freqency collocation bigrams are **********************')\n",
    "print(count_collocation.most_common(20))\n",
    "print(\"**********************************************\")\n",
    "print('size of bi-gram counter is ',len(count_collocation))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the low frequency bigrams\n",
    "counter_col = util.remove_rare_term(count_collocation,rare_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of bi-gram counter after removing rare bigrame is  70477\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('size of bi-gram counter after removing rare bigrame is ',len(counter_col))\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(counter_col.items(), key=util.operator.itemgetter(1))\n",
    "sorted_x.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the top 10 colloation words are*********************************\n",
      "[(('tomorrow', 'positive_corpus'), 3740), (('may', 'neutral_corpus'), 3180), (('tomorrow', 'neutral_corpus'), 3058), (('may', 'positive_corpus'), 2474), (('day', 'positive_corpus'), 2312), (('see', 'positive_corpus'), 1724), (('may', 'negative_corpus'), 1700), (('night', 'positive_corpus'), 1519), ((\"i'm\", 'positive_corpus'), 1450), (('going', 'neutral_corpus'), 1426)]\n",
      "**********************************************\n",
      "the most low 10 colloation r words are*********************************\n",
      "[(('2nd', 'share'), 6), (('2nd', 'including'), 6), (('worst', 'team'), 6), (('including', 'negative_corpus'), 6), (('hear', \"that's\"), 6), (('hear', 'could'), 6), (('tony', 'night'), 6), (('romo', 'sunday'), 6), (('cause', 'sunday'), 6), (('tina', 'january'), 6)]\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('the top 10 colloation words are*********************************')\n",
    "print(sorted_x[:10])\n",
    "print(\"**********************************************\")\n",
    "\n",
    "sorted_x.reverse()\n",
    "print('the most low 10 colloation r words are*********************************')\n",
    "print(sorted_x[:10])\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct word occurrences matrix and PMI matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = [['A', 'B'], ['C', 'B'], ['A', 'B', 'C', 'D']]\n",
    "# counter_uni = util.word_counter(document)\n",
    "# counter_col = util.collocation_counter(document)\n",
    "df_coll,matrix_coll = util.construct_word_occurrence_matrix(counter_uni,counter_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 match  plus  tomorrow  busy     day  awareness  day's  \\\n",
      "match             21.0   0.0      39.0   0.0     7.0        0.0    0.0   \n",
      "plus               0.0   0.0      22.0   0.0     9.0        0.0    0.0   \n",
      "tomorrow          39.0  22.0     104.0  35.0  1004.0        7.0    0.0   \n",
      "busy               0.0   0.0      35.0   0.0    29.0        0.0    0.0   \n",
      "day                7.0   9.0    1004.0  29.0   517.0       15.0    0.0   \n",
      "awareness          0.0   0.0       7.0   0.0    15.0        0.0    0.0   \n",
      "day's              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "neutral_corpus   166.0  39.0    3058.0  42.0  1388.0       11.0    0.0   \n",
      "areas              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "new                0.0  11.0     315.0   0.0   144.0        0.0    0.0   \n",
      "england            0.0   0.0       7.0   0.0     0.0        0.0    0.0   \n",
      "could              9.0   0.0      90.0   0.0    45.0        0.0    0.0   \n",
      "see               13.0  10.0     847.0   6.0   197.0        0.0    0.0   \n",
      "first             11.0   0.0     180.0   0.0   131.0        0.0    0.0   \n",
      "season             6.0   0.0      55.0   0.0    34.0        0.0    0.0   \n",
      "tuesday           10.0   0.0      13.0   0.0    97.0        0.0    0.0   \n",
      "2nd               25.0   0.0      16.0   0.0   134.0        0.0    0.0   \n",
      "worst              0.0   0.0       9.0   0.0    22.0        0.0    0.0   \n",
      "qb                 0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "definitely         0.0   0.0      32.0   0.0     7.0        0.0    0.0   \n",
      "tony               0.0   0.0       8.0   0.0     0.0        0.0    0.0   \n",
      "romo               0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "man                8.0   0.0      54.0   0.0    21.0        0.0    0.0   \n",
      "likes              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "share              0.0   0.0       8.0   0.0     0.0        0.0    0.0   \n",
      "ball               0.0   0.0      21.0   0.0     0.0        0.0    0.0   \n",
      "everyone           0.0   0.0     103.0   0.0    52.0        0.0    0.0   \n",
      "including          0.0   0.0       7.0   0.0     9.0        0.0    0.0   \n",
      "team              12.0   0.0      57.0   0.0    20.0        0.0    0.0   \n",
      "negative_corpus   30.0  16.0     994.0  15.0   482.0        0.0    6.0   \n",
      "...                ...   ...       ...   ...     ...        ...    ...   \n",
      "pogba              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "nicki's            0.0   0.0       6.0   0.0     0.0        0.0    0.0   \n",
      "carey              0.0   0.0       6.0   0.0     0.0        0.0    0.0   \n",
      "iran's             0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "deflategate        0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "ortiz              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "kurds              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "tiebreak           0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "briana             0.0   0.0      18.0   0.0    11.0        0.0    0.0   \n",
      "thor's             0.0   0.0       0.0   0.0    28.0        0.0    0.0   \n",
      "blanchett          0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "hebdo              0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "briana's           0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "blair's            0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "blackstar          0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "mtvstars           0.0   0.0      19.0   0.0     0.0        0.0    0.0   \n",
      "lamar's            0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "kardashian's       0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "arabia's           0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "xxl                0.0   0.0      17.0   0.0     0.0        0.0    0.0   \n",
      "bieber's           0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "erdogan            0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "elxn42             0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "erdogan's          0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "federer's          0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "fleetwood          0.0   0.0      13.0   0.0     0.0        0.0    0.0   \n",
      "ihop               0.0   0.0      59.0   0.0     6.0        0.0    0.0   \n",
      "jay-z's            0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "lexus              0.0   0.0      11.0   0.0     0.0        0.0    0.0   \n",
      "hoverboard         0.0   0.0       0.0   0.0     0.0        0.0    0.0   \n",
      "\n",
      "                 neutral_corpus  areas     new     ...      bieber's  erdogan  \\\n",
      "match                     166.0    0.0     0.0     ...           0.0      0.0   \n",
      "plus                       39.0    0.0    11.0     ...           0.0      0.0   \n",
      "tomorrow                 3058.0    0.0   315.0     ...           0.0      0.0   \n",
      "busy                       42.0    0.0     0.0     ...           0.0      0.0   \n",
      "day                      1388.0    0.0   144.0     ...           0.0      0.0   \n",
      "awareness                  11.0    0.0     0.0     ...           0.0      0.0   \n",
      "day's                       0.0    0.0     0.0     ...           0.0      0.0   \n",
      "neutral_corpus              0.0   10.0  1009.0     ...           9.0     42.0   \n",
      "areas                      10.0    0.0     0.0     ...           0.0      0.0   \n",
      "new                      1009.0    0.0    82.0     ...           0.0     10.0   \n",
      "england                    45.0    0.0    16.0     ...           0.0      0.0   \n",
      "could                     217.0    0.0    11.0     ...           0.0      0.0   \n",
      "see                      1029.0    0.0    81.0     ...           0.0      0.0   \n",
      "first                     591.0    0.0    58.0     ...           0.0      0.0   \n",
      "season                    343.0    0.0    62.0     ...           0.0      0.0   \n",
      "tuesday                   470.0    0.0    54.0     ...           0.0      0.0   \n",
      "2nd                       907.0    0.0    56.0     ...           0.0      0.0   \n",
      "worst                      28.0    0.0     0.0     ...           0.0      0.0   \n",
      "qb                         17.0    0.0     0.0     ...           0.0      0.0   \n",
      "definitely                 26.0    0.0     0.0     ...           0.0      0.0   \n",
      "tony                       84.0    0.0     0.0     ...           0.0      0.0   \n",
      "romo                       29.0    0.0     0.0     ...           0.0      0.0   \n",
      "man                       243.0    0.0    15.0     ...           0.0      0.0   \n",
      "likes                      18.0    0.0     0.0     ...           0.0      0.0   \n",
      "share                      47.0    0.0     0.0     ...           0.0      0.0   \n",
      "ball                       74.0    0.0     0.0     ...           0.0      0.0   \n",
      "everyone                  118.0    0.0    11.0     ...           0.0      0.0   \n",
      "including                  30.0    0.0     0.0     ...           0.0      0.0   \n",
      "team                      241.0    0.0    17.0     ...           0.0      0.0   \n",
      "negative_corpus             0.0    0.0   162.0     ...           0.0     50.0   \n",
      "...                         ...    ...     ...     ...           ...      ...   \n",
      "pogba                      11.0    0.0     0.0     ...           0.0      0.0   \n",
      "nicki's                    14.0    0.0     0.0     ...           0.0      0.0   \n",
      "carey                      19.0    0.0     0.0     ...           0.0      0.0   \n",
      "iran's                      0.0    0.0     0.0     ...           0.0      0.0   \n",
      "deflategate                13.0    0.0     0.0     ...           0.0      0.0   \n",
      "ortiz                      11.0    0.0     0.0     ...           0.0      0.0   \n",
      "kurds                       0.0    0.0     0.0     ...           0.0      8.0   \n",
      "tiebreak                    0.0    0.0     0.0     ...           0.0      0.0   \n",
      "briana                     84.0    0.0     7.0     ...           0.0      0.0   \n",
      "thor's                     17.0    0.0     0.0     ...           0.0      0.0   \n",
      "blanchett                  30.0    0.0     9.0     ...           0.0      0.0   \n",
      "hebdo                      88.0    0.0     0.0     ...           0.0      0.0   \n",
      "briana's                    8.0    0.0     0.0     ...           0.0      0.0   \n",
      "blair's                     9.0    0.0     0.0     ...           0.0      0.0   \n",
      "blackstar                  13.0    0.0    13.0     ...           0.0      0.0   \n",
      "mtvstars                   38.0    0.0     0.0     ...           0.0      0.0   \n",
      "lamar's                     8.0    0.0     0.0     ...           0.0      0.0   \n",
      "kardashian's               10.0    0.0     0.0     ...           0.0      0.0   \n",
      "arabia's                    7.0    0.0     0.0     ...           0.0      0.0   \n",
      "xxl                         9.0    0.0     0.0     ...           0.0      0.0   \n",
      "bieber's                    9.0    0.0     0.0     ...           0.0      0.0   \n",
      "erdogan                    42.0    0.0    10.0     ...           0.0      0.0   \n",
      "elxn42                      7.0    0.0     0.0     ...           0.0      0.0   \n",
      "erdogan's                   6.0    0.0     0.0     ...           0.0      0.0   \n",
      "federer's                   0.0    0.0     0.0     ...           0.0      0.0   \n",
      "fleetwood                  24.0    0.0     0.0     ...           0.0      0.0   \n",
      "ihop                       27.0    0.0     0.0     ...           0.0      0.0   \n",
      "jay-z's                     0.0    0.0     0.0     ...           0.0      0.0   \n",
      "lexus                      42.0    0.0    18.0     ...           0.0      0.0   \n",
      "hoverboard                  0.0    0.0     0.0     ...           0.0      0.0   \n",
      "\n",
      "                 elxn42  erdogan's  federer's  fleetwood  ihop  jay-z's  \\\n",
      "match               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "plus                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "tomorrow            0.0        0.0        0.0       13.0  59.0      0.0   \n",
      "busy                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "day                 0.0        0.0        0.0        0.0   6.0      0.0   \n",
      "awareness           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "day's               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "neutral_corpus      7.0        6.0        0.0       24.0  27.0      0.0   \n",
      "areas               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "new                 0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "england             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "could               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "see                 0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "first               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "season              0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "tuesday             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "2nd                 0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "worst               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "qb                  0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "definitely          0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "tony                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "romo                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "man                 0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "likes               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "share               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "ball                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "everyone            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "including           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "team                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "negative_corpus     0.0        6.0        0.0        0.0   0.0      0.0   \n",
      "...                 ...        ...        ...        ...   ...      ...   \n",
      "pogba               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "nicki's             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "carey               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "iran's              0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "deflategate         0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "ortiz               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "kurds               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "tiebreak            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "briana              0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "thor's              0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "blanchett           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "hebdo               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "briana's            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "blair's             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "blackstar           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "mtvstars            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "lamar's             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "kardashian's        0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "arabia's            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "xxl                 0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "bieber's            0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "erdogan             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "elxn42              0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "erdogan's           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "federer's           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "fleetwood           0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "ihop                0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "jay-z's             0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "lexus               0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "hoverboard          0.0        0.0        0.0        0.0   0.0      0.0   \n",
      "\n",
      "                 lexus  hoverboard  \n",
      "match              0.0         0.0  \n",
      "plus               0.0         0.0  \n",
      "tomorrow          11.0         0.0  \n",
      "busy               0.0         0.0  \n",
      "day                0.0         0.0  \n",
      "awareness          0.0         0.0  \n",
      "day's              0.0         0.0  \n",
      "neutral_corpus    42.0         0.0  \n",
      "areas              0.0         0.0  \n",
      "new               18.0         0.0  \n",
      "england            0.0         0.0  \n",
      "could              0.0         0.0  \n",
      "see                9.0         0.0  \n",
      "first              0.0         0.0  \n",
      "season             0.0         0.0  \n",
      "tuesday            0.0         0.0  \n",
      "2nd                7.0         0.0  \n",
      "worst              0.0         0.0  \n",
      "qb                 0.0         0.0  \n",
      "definitely         0.0         0.0  \n",
      "tony               0.0         0.0  \n",
      "romo               0.0         0.0  \n",
      "man                0.0         0.0  \n",
      "likes              0.0         0.0  \n",
      "share              0.0         0.0  \n",
      "ball               0.0         0.0  \n",
      "everyone           0.0         0.0  \n",
      "including          0.0         0.0  \n",
      "team               0.0         0.0  \n",
      "negative_corpus    8.0         0.0  \n",
      "...                ...         ...  \n",
      "pogba              0.0         0.0  \n",
      "nicki's            0.0         0.0  \n",
      "carey              0.0         0.0  \n",
      "iran's             0.0         0.0  \n",
      "deflategate        0.0         0.0  \n",
      "ortiz              0.0         0.0  \n",
      "kurds              0.0         0.0  \n",
      "tiebreak           0.0         0.0  \n",
      "briana             0.0         0.0  \n",
      "thor's             0.0         0.0  \n",
      "blanchett          0.0         0.0  \n",
      "hebdo              0.0         0.0  \n",
      "briana's           0.0         0.0  \n",
      "blair's            0.0         0.0  \n",
      "blackstar          0.0         0.0  \n",
      "mtvstars           0.0         0.0  \n",
      "lamar's            0.0         0.0  \n",
      "kardashian's       0.0         0.0  \n",
      "arabia's           0.0         0.0  \n",
      "xxl                0.0         0.0  \n",
      "bieber's           0.0         0.0  \n",
      "erdogan            0.0         0.0  \n",
      "elxn42             0.0         0.0  \n",
      "erdogan's          0.0         0.0  \n",
      "federer's          0.0         0.0  \n",
      "fleetwood          0.0         0.0  \n",
      "ihop               0.0         0.0  \n",
      "jay-z's            0.0         0.0  \n",
      "lexus             23.0        34.0  \n",
      "hoverboard        34.0         0.0  \n",
      "\n",
      "[6012 rows x 6012 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_index = df_coll.index.tolist()\n",
    "names_header = df_coll.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying laplace smoothed, parameter is 1\n"
     ]
    }
   ],
   "source": [
    "dff_pmi,ppmi_matrix = util.PPMI_matrix(names_index,names_header,matrix_coll,la_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    match      plus  tomorrow      busy       day  awareness  \\\n",
      "match            3.806133  0.000000  1.484869  0.000000  0.000000   0.000000   \n",
      "plus             0.000000  0.000000  0.979114  0.000000  0.508005   0.006007   \n",
      "tomorrow         1.484869  0.979114  0.000000  1.657060  3.682685   0.000000   \n",
      "busy             0.000000  0.000000  1.657060  0.000000  2.124551   0.037591   \n",
      "day              0.000000  0.508005  3.682685  2.124551  3.457040   1.260161   \n",
      "awareness        0.000000  0.006007  0.000000  0.037591  1.260161   0.080091   \n",
      "day's            0.000000  0.012695  0.000000  0.044279  0.000000   0.086779   \n",
      "neutral_corpus   1.946663  0.177497  2.958042  0.313417  2.549554   0.000000   \n",
      "areas            0.000000  0.013653  0.000000  0.045237  0.000000   0.087737   \n",
      "new              0.000000  1.714682  2.957129  0.000000  2.563783   0.000000   \n",
      "england          0.000000  0.000000  0.000000  0.000000  0.000000   0.023774   \n",
      "could            2.501459  0.000000  2.503565  0.000000  2.249858   0.000000   \n",
      "see              1.176079  1.120766  3.912883  0.500273  2.544845   0.000000   \n",
      "first            2.066804  0.000000  2.797927  0.000000  3.073000   0.000000   \n",
      "season           1.646412  0.000000  1.462652  0.000000  1.515105   0.000000   \n",
      "tuesday          2.278479  0.000000  0.000000  0.000000  2.980522   0.000000   \n",
      "2nd              2.633491  0.000000  0.000000  0.000000  2.556631   0.000000   \n",
      "worst            0.000000  0.000000  0.000000  0.000000  1.680507   0.000000   \n",
      "qb               0.000000  0.000000  0.000000  0.017946  0.000000   0.060447   \n",
      "definitely       0.000000  0.000000  1.489795  0.000000  0.175926   0.000000   \n",
      "tony             0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "romo             0.000000  0.000000  0.000000  0.017711  0.000000   0.060211   \n",
      "man              2.239523  0.000000  1.667196  0.000000  1.075794   0.000000   \n",
      "likes            0.000000  0.005293  0.000000  0.036876  0.000000   0.079377   \n",
      "share            0.000000  0.000000  0.000000  0.008573  0.000000   0.051074   \n",
      "ball             0.000000  0.000000  0.864490  0.000000  0.000000   0.000000   \n",
      "everyone         0.000000  0.000000  2.828144  0.000000  2.586151   0.000000   \n",
      "including        0.000000  0.000000  0.000000  0.026907  0.571405   0.069407   \n",
      "team             2.883267  0.000000  1.857047  0.000000  1.121909   0.000000   \n",
      "negative_corpus  1.064711  0.490588  2.885306  0.434708  2.573158   0.000000   \n",
      "...                   ...       ...       ...       ...       ...        ...   \n",
      "pogba            0.000000  0.009348  0.000000  0.040931  0.000000   0.083432   \n",
      "nicki's          0.000000  0.004578  0.000000  0.036161  0.000000   0.078662   \n",
      "carey            0.000000  0.000000  0.000000  0.000000  0.000000   0.021026   \n",
      "iran's           0.000000  0.014612  0.000000  0.046195  0.000000   0.088696   \n",
      "deflategate      0.000000  0.001962  0.000000  0.033545  0.000000   0.076046   \n",
      "ortiz            0.000000  0.000537  0.000000  0.032120  0.000000   0.074621   \n",
      "kurds            0.000000  0.010781  0.000000  0.042365  0.000000   0.084865   \n",
      "tiebreak         0.000000  0.010064  0.000000  0.041647  0.000000   0.084148   \n",
      "briana           0.000000  0.000000  0.639280  0.000000  0.706841   0.000000   \n",
      "thor's           0.000000  0.000000  0.000000  0.022183  2.102735   0.064684   \n",
      "blanchett        0.000000  0.000000  0.000000  0.000000  0.000000   0.032048   \n",
      "hebdo            0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
      "briana's         0.000000  0.011260  0.000000  0.042843  0.000000   0.085344   \n",
      "blair's          0.000000  0.010064  0.000000  0.041647  0.000000   0.084148   \n",
      "blackstar        0.000000  0.000000  0.000000  0.018651  0.000000   0.061152   \n",
      "mtvstars         0.000000  0.000000  0.756356  0.000000  0.000000   0.000000   \n",
      "lamar's          0.000000  0.000062  0.000000  0.031645  0.000000   0.074146   \n",
      "kardashian's     0.000000  0.004578  0.000000  0.036161  0.000000   0.078662   \n",
      "arabia's         0.000000  0.011499  0.000000  0.043082  0.000000   0.085583   \n",
      "xxl              0.000000  0.000000  0.593463  0.000000  0.000000   0.000000   \n",
      "bieber's         0.000000  0.006246  0.000000  0.037829  0.000000   0.080330   \n",
      "erdogan          0.000000  0.000000  0.000000  0.000000  0.000000   0.018284   \n",
      "elxn42           0.000000  0.009348  0.000000  0.040931  0.000000   0.083432   \n",
      "erdogan's        0.000000  0.010781  0.000000  0.042365  0.000000   0.084865   \n",
      "federer's        0.000000  0.013653  0.000000  0.045237  0.000000   0.087737   \n",
      "fleetwood        0.000000  0.000000  0.260193  0.000000  0.000000   0.003293   \n",
      "ihop             0.000000  0.000000  2.377461  0.000000  0.008451   0.021026   \n",
      "jay-z's          0.000000  0.014612  0.000000  0.046195  0.000000   0.088696   \n",
      "lexus            0.000000  0.000000  0.045276  0.000000  0.000000   0.010769   \n",
      "hoverboard       0.000000  0.001487  0.000000  0.033070  0.000000   0.075571   \n",
      "\n",
      "                    day's  neutral_corpus     areas       new     ...      \\\n",
      "match            0.000000        1.946663  0.000000  0.000000     ...       \n",
      "plus             0.012695        0.177497  0.013653  1.714682     ...       \n",
      "tomorrow         0.000000        2.958042  0.000000  2.957129     ...       \n",
      "busy             0.044279        0.313417  0.045237  0.000000     ...       \n",
      "day              0.000000        2.549554  0.000000  2.563783     ...       \n",
      "awareness        0.086779        0.000000  0.087737  0.000000     ...       \n",
      "day's            0.093467        0.000000  0.094425  0.000000     ...       \n",
      "neutral_corpus   0.000000        0.000000  0.000000  3.033505     ...       \n",
      "areas            0.094425        0.000000  0.095383  0.000000     ...       \n",
      "new              0.000000        3.033505  0.000000  2.702555     ...       \n",
      "england          0.030462        0.396897  0.031420  2.234949     ...       \n",
      "could            0.000000        2.163972  0.000000  1.254901     ...       \n",
      "see              0.000000        2.593409  0.000000  2.216683     ...       \n",
      "first            0.000000        2.907551  0.000000  2.854892     ...       \n",
      "season           0.000000        2.481579  0.000000  3.306744     ...       \n",
      "tuesday          0.000000        2.914887  0.000000  3.090814     ...       \n",
      "2nd              0.000000        2.975856  0.000000  2.256348     ...       \n",
      "worst            0.000000        0.000000  0.000000  0.000000     ...       \n",
      "qb               0.067135        0.000000  0.068093  0.000000     ...       \n",
      "definitely       0.002544        0.000000  0.003502  0.000000     ...       \n",
      "tony             0.000000        1.212282  0.000000  0.000000     ...       \n",
      "romo             0.066899        0.000000  0.067857  0.000000     ...       \n",
      "man              0.000000        2.216591  0.000000  1.560005     ...       \n",
      "likes            0.086065        0.000000  0.087023  0.000000     ...       \n",
      "share            0.057762        0.485598  0.058720  0.000000     ...       \n",
      "ball             0.000000        1.033894  0.000000  0.000000     ...       \n",
      "everyone         0.000000        1.422540  0.000000  1.386835     ...       \n",
      "including        0.076095        0.000000  0.077053  0.000000     ...       \n",
      "team             0.000000        2.317947  0.000000  1.843159     ...       \n",
      "negative_corpus  0.000000        0.000000  0.000000  1.949649     ...       \n",
      "...                   ...             ...       ...       ...     ...       \n",
      "pogba            0.090120        0.000000  0.091078  0.000000     ...       \n",
      "nicki's          0.085350        0.000000  0.086308  0.000000     ...       \n",
      "carey            0.027714        0.000000  0.028672  0.000000     ...       \n",
      "iran's           0.095384        0.000000  0.096342  0.000000     ...       \n",
      "deflategate      0.082734        0.000000  0.083692  0.000000     ...       \n",
      "ortiz            0.081309        0.000000  0.082267  0.000000     ...       \n",
      "kurds            0.091553        0.000000  0.092511  0.000000     ...       \n",
      "tiebreak         0.090836        0.000000  0.091794  0.000000     ...       \n",
      "briana           0.000000        1.200761  0.000000  1.065520     ...       \n",
      "thor's           0.071372        0.000000  0.072330  0.000000     ...       \n",
      "blanchett        0.038736        0.000000  0.039694  1.477688     ...       \n",
      "hebdo            0.000000        1.213337  0.000000  0.000000     ...       \n",
      "briana's         0.092032        0.000000  0.092990  0.000000     ...       \n",
      "blair's          0.090836        0.000000  0.091794  0.000000     ...       \n",
      "blackstar        0.067840        0.000000  0.068798  1.992219     ...       \n",
      "mtvstars         0.000000        0.119847  0.000000  0.000000     ...       \n",
      "lamar's          0.080834        0.000000  0.081792  0.000000     ...       \n",
      "kardashian's     0.085350        0.000000  0.086308  0.000000     ...       \n",
      "arabia's         0.092271        0.000000  0.093229  0.000000     ...       \n",
      "xxl              0.000000        0.000000  0.000000  0.000000     ...       \n",
      "bieber's         0.087018        0.000000  0.087976  0.000000     ...       \n",
      "erdogan          0.024972        0.294110  0.025930  1.601428     ...       \n",
      "elxn42           0.090120        0.000000  0.091078  0.000000     ...       \n",
      "erdogan's        0.091553        0.000000  0.092511  0.000000     ...       \n",
      "federer's        0.094425        0.000000  0.095383  0.000000     ...       \n",
      "fleetwood        0.009982        0.000000  0.010939  0.000000     ...       \n",
      "ihop             0.027714        0.000000  0.028672  0.000000     ...       \n",
      "jay-z's          0.095384        0.000000  0.096342  0.000000     ...       \n",
      "lexus            0.017457        0.286596  0.018415  2.382409     ...       \n",
      "hoverboard       0.082259        0.000000  0.083217  0.000000     ...       \n",
      "\n",
      "                 bieber's   erdogan    elxn42  erdogan's  federer's  \\\n",
      "match            0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "plus             0.006246  0.000000  0.009348   0.010781   0.013653   \n",
      "tomorrow         0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "busy             0.037829  0.000000  0.040931   0.042365   0.045237   \n",
      "day              0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "awareness        0.080330  0.018284  0.083432   0.084865   0.087737   \n",
      "day's            0.087018  0.024972  0.090120   0.091553   0.094425   \n",
      "neutral_corpus   0.000000  0.294110  0.000000   0.000000   0.000000   \n",
      "areas            0.087976  0.025930  0.091078   0.092511   0.095383   \n",
      "new              0.000000  1.601428  0.000000   0.000000   0.000000   \n",
      "england          0.024012  0.000000  0.027114   0.028548   0.031420   \n",
      "could            0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "see              0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "first            0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "season           0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "tuesday          0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "2nd              0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "worst            0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "qb               0.060685  0.000000  0.063787   0.065221   0.068093   \n",
      "definitely       0.000000  0.000000  0.000000   0.000630   0.003502   \n",
      "tony             0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "romo             0.060450  0.000000  0.063552   0.064985   0.067857   \n",
      "man              0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "likes            0.079615  0.017569  0.082717   0.084151   0.087023   \n",
      "share            0.051312  0.000000  0.054414   0.055848   0.058720   \n",
      "ball             0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "everyone         0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "including        0.069646  0.007600  0.072748   0.074181   0.077053   \n",
      "team             0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "negative_corpus  0.000000  2.087827  0.000000   0.000000   0.000000   \n",
      "...                   ...       ...       ...        ...        ...   \n",
      "pogba            0.083670  0.021624  0.086772   0.088206   0.091078   \n",
      "nicki's          0.078901  0.016855  0.082002   0.083436   0.086308   \n",
      "carey            0.021265  0.000000  0.024366   0.025800   0.028672   \n",
      "iran's           0.088934  0.026888  0.092036   0.093470   0.096342   \n",
      "deflategate      0.076284  0.014238  0.079386   0.080820   0.083692   \n",
      "ortiz            0.074859  0.012813  0.077961   0.079395   0.082267   \n",
      "kurds            0.085104  3.192983  0.088206   0.089639   0.092511   \n",
      "tiebreak         0.084387  0.022341  0.087488   0.088922   0.091794   \n",
      "briana           0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "thor's           0.064923  0.002877  0.068024   0.069458   0.072330   \n",
      "blanchett        0.032286  0.000000  0.035388   0.036822   0.039694   \n",
      "hebdo            0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "briana's         0.085582  0.023536  0.088684   0.090118   0.092990   \n",
      "blair's          0.084387  0.022341  0.087488   0.088922   0.091794   \n",
      "blackstar        0.061390  0.000000  0.064492   0.065926   0.068798   \n",
      "mtvstars         0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "lamar's          0.074384  0.012339  0.077486   0.078920   0.081792   \n",
      "kardashian's     0.078901  0.016855  0.082002   0.083436   0.086308   \n",
      "arabia's         0.085821  0.023775  0.088923   0.090357   0.093229   \n",
      "xxl              0.000000  0.000000  0.000000   0.000000   0.000000   \n",
      "bieber's         0.080568  0.018522  0.083670   0.085104   0.087976   \n",
      "erdogan          0.018522  0.000000  0.021624   0.023058   0.025930   \n",
      "elxn42           0.083670  0.021624  0.086772   0.088206   0.091078   \n",
      "erdogan's        0.085104  0.023058  0.088206   0.089639   0.092511   \n",
      "federer's        0.087976  0.025930  0.091078   0.092511   0.095383   \n",
      "fleetwood        0.003532  0.000000  0.006634   0.008067   0.010939   \n",
      "ihop             0.021265  0.000000  0.024366   0.025800   0.028672   \n",
      "jay-z's          0.088934  0.026888  0.092036   0.093470   0.096342   \n",
      "lexus            0.011008  0.000000  0.014109   0.015543   0.018415   \n",
      "hoverboard       0.075809  0.013763  0.078911   0.080345   0.083217   \n",
      "\n",
      "                 fleetwood      ihop   jay-z's     lexus  hoverboard  \n",
      "match             0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "plus              0.000000  0.000000  0.014612  0.000000    0.001487  \n",
      "tomorrow          0.260193  2.377461  0.000000  0.045276    0.000000  \n",
      "busy              0.000000  0.000000  0.046195  0.000000    0.033070  \n",
      "day               0.000000  0.008451  0.000000  0.000000    0.000000  \n",
      "awareness         0.003293  0.021026  0.088696  0.010769    0.075571  \n",
      "day's             0.009982  0.027714  0.095384  0.017457    0.082259  \n",
      "neutral_corpus    0.000000  0.000000  0.000000  0.286596    0.000000  \n",
      "areas             0.010939  0.028672  0.096342  0.018415    0.083217  \n",
      "new               0.000000  0.000000  0.000000  2.382409    0.000000  \n",
      "england           0.000000  0.000000  0.032378  0.000000    0.019253  \n",
      "could             0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "see               0.000000  0.000000  0.000000  0.988025    0.000000  \n",
      "first             0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "season            0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "tuesday           0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "2nd               0.000000  0.000000  0.000000  1.230424    0.000000  \n",
      "worst             0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "qb                0.000000  0.001381  0.069051  0.000000    0.055926  \n",
      "definitely        0.000000  0.000000  0.004461  0.000000    0.000000  \n",
      "tony              0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "romo              0.000000  0.001146  0.068816  0.000000    0.055691  \n",
      "man               0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "likes             0.002579  0.020311  0.087981  0.010054    0.074856  \n",
      "share             0.000000  0.000000  0.059678  0.000000    0.046553  \n",
      "ball              0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "everyone          0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "including         0.000000  0.010342  0.078012  0.000085    0.064887  \n",
      "team              0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "negative_corpus   0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "...                    ...       ...       ...       ...         ...  \n",
      "pogba             0.006634  0.024366  0.092036  0.014109    0.078911  \n",
      "nicki's           0.001864  0.019597  0.087267  0.009340    0.074142  \n",
      "carey             0.000000  0.000000  0.029631  0.000000    0.016505  \n",
      "iran's            0.011898  0.029631  0.097301  0.019374    0.084175  \n",
      "deflategate       0.000000  0.016981  0.084651  0.006724    0.071525  \n",
      "ortiz             0.000000  0.015556  0.083225  0.005299    0.070100  \n",
      "kurds             0.008067  0.025800  0.093470  0.015543    0.080345  \n",
      "tiebreak          0.007350  0.025083  0.092753  0.014826    0.079628  \n",
      "briana            0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "thor's            0.000000  0.005619  0.073289  0.000000    0.060164  \n",
      "blanchett         0.000000  0.000000  0.040653  0.000000    0.027527  \n",
      "hebdo             0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "briana's          0.008546  0.026278  0.093948  0.016021    0.080823  \n",
      "blair's           0.007350  0.025083  0.092753  0.014826    0.079628  \n",
      "blackstar         0.000000  0.002087  0.069757  0.000000    0.056631  \n",
      "mtvstars          0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "lamar's           0.000000  0.015081  0.082751  0.004824    0.069625  \n",
      "kardashian's      0.001864  0.019597  0.087267  0.009340    0.074142  \n",
      "arabia's          0.008785  0.026518  0.094187  0.016261    0.081062  \n",
      "xxl               0.000000  0.000000  0.000000  0.000000    0.000000  \n",
      "bieber's          0.003532  0.021265  0.088934  0.011008    0.075809  \n",
      "erdogan           0.000000  0.000000  0.026888  0.000000    0.013763  \n",
      "elxn42            0.006634  0.024366  0.092036  0.014109    0.078911  \n",
      "erdogan's         0.008067  0.025800  0.093470  0.015543    0.080345  \n",
      "federer's         0.010939  0.028672  0.096342  0.018415    0.083217  \n",
      "fleetwood         0.000000  0.000000  0.011898  0.000000    0.000000  \n",
      "ihop              0.000000  0.000000  0.029631  0.000000    0.016505  \n",
      "jay-z's           0.011898  0.029631  0.097301  0.019374    0.084175  \n",
      "lexus             0.000000  0.000000  0.019374  4.526409    5.135532  \n",
      "hoverboard        0.000000  0.016505  0.084175  5.135532    0.071050  \n",
      "\n",
      "[6012 rows x 6012 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dff_pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest PPMI value tuples is****************************\n",
      "('hogan', 'hulk')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('the highest PPMI value tuples is****************************')\n",
    "print(dff_pmi.stack().index[util.np.argmax(ppmi_matrix)])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply symmetrics SVD to get the word and context embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,C = util.construct_word_embedding(dimension,ppmi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.16366987e-01  2.24955101e-01 -2.92381746e-01 ...  4.61465890e-02\n",
      "  -2.97033399e-01 -1.52938188e-01]\n",
      " [-1.32775129e-01  1.62248474e-02 -2.09789931e-01 ...  1.12382337e-01\n",
      "  -5.24645547e-02  6.80586015e-02]\n",
      " [-1.84025695e+00  6.29359755e-01  1.55949558e+00 ...  1.80931210e-01\n",
      "   1.05105315e-01  1.00406231e-01]\n",
      " ...\n",
      " [-1.04851923e-01 -2.95116581e-01  7.05089457e-03 ...  1.38731712e-03\n",
      "  -9.81751919e-05  1.07269029e-03]\n",
      " [-1.09314476e-01 -9.31641886e-03 -1.21067767e-01 ... -3.17927192e-02\n",
      "  -1.15450535e-01  7.64422321e-02]\n",
      " [-8.95848471e-02 -2.51409662e-01  7.49018938e-03 ...  5.62255363e-03\n",
      "  -1.89250776e-02 -1.26025147e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W is**********************************************\n",
      "(6012, 100)\n",
      "**********************************************\n",
      "shape of C is*********************************************\n",
      "(6012, 100)\n",
      "**********************************************\n"
     ]
    }
   ],
   "source": [
    "print('shape of W is**********************************************')\n",
    "print(W.shape)\n",
    "print(\"**********************************************\")\n",
    "\n",
    "print('shape of C is*********************************************')\n",
    "print(C.shape)\n",
    "print(\"**********************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export word embedding to csv file!!!\n"
     ]
    }
   ],
   "source": [
    "header = dff_pmi.index.tolist()\n",
    "frame=util.to_csv(W,header,'test_svd_embedding.csv')\n",
    "print('export word embedding to csv file!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "dataSetI = [3, 45, 7, 2]\n",
    "dataSetII = [3, 54,7, 2]\n",
    "result = spatial.distance.cosine(dataSetI, dataSetII)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = cosine_similarity(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1=frame.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([7], dtype='int64')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1[frame1['index'] == 'neutral_corpus'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01797303,  0.10714496, -0.06409525, ...,  0.87612823,\n",
       "        0.08294716,  0.85315428])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_matrix[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  56,   12,    4,  157,   90,  166,   76,   58,  457,   83,    2,\n",
       "          7,   48,   59,  156,  399,  179,  103,  143,    9,  219,  210,\n",
       "        309,  349,  155,  479,   77,   47,   13,  414,  290,  154,  483,\n",
       "         70,   16,  209,  129,  421,  107,  214,   31,  342,  291,  415,\n",
       "        120,  108,  313,  731,   51,  435,  408,  468,   29,  594,  838,\n",
       "        416,  598,  254,  486,  260,  105,  489,  304,   81, 1006,  109,\n",
       "        279,  318,  272, 1070,  581,  625,  434,  218,  308,  123,  665,\n",
       "       1119,   26,  378, 1246,  199,  446,  351,  306,  208,  813,  782,\n",
       "        148,  255, 2336,  354,  343, 1134, 1188,  139,   22,  161,  165,\n",
       "        733])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array(cos_sim_matrix[56])\n",
    "\n",
    "order = arr.argsort()[-100:][::-1]\n",
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_corpus\n",
      "see\n",
      "day\n",
      "one\n",
      "get\n",
      "time\n",
      "going\n",
      "good\n",
      "today\n",
      "i'm\n",
      "tomorrow\n",
      "neutral_corpus\n",
      "night\n",
      "love\n",
      "like\n",
      "go\n",
      "friday\n",
      "saturday\n",
      "last\n",
      "new\n",
      "tonight\n",
      "come\n",
      "great\n",
      "best\n",
      "happy\n",
      "know\n",
      "back\n",
      "sunday\n",
      "first\n",
      "1st\n",
      "can't\n",
      "want\n",
      "really\n",
      "think\n",
      "2nd\n",
      "still\n",
      "got\n",
      "make\n",
      "hope\n",
      "2\n",
      "us\n",
      "birthday\n",
      "wait\n",
      "would\n",
      "monday\n",
      "next\n",
      "coming\n",
      "3\n",
      "may\n",
      "watch\n",
      "gonna\n",
      "show\n",
      "negative_corpus\n",
      "big\n",
      "much\n",
      "better\n",
      "live\n",
      "3rd\n",
      "i'll\n",
      "well\n",
      "game\n",
      "morning\n",
      "weekend\n",
      "work\n",
      "fun\n",
      "thursday\n",
      "play\n",
      "watching\n",
      "1\n",
      "year\n",
      "way\n",
      "right\n",
      "free\n",
      "excited\n",
      "concert\n",
      "need\n",
      "ever\n",
      "also\n",
      "everyone\n",
      "even\n",
      "amazing\n",
      "4\n",
      "lol\n",
      "getting\n",
      "sat\n",
      "music\n",
      "seeing\n",
      "every\n",
      "since\n",
      "saw\n",
      "enjoy\n",
      "win\n",
      "september\n",
      "song\n",
      "guys\n",
      "week\n",
      "man\n",
      "playing\n",
      "4th\n",
      "hey\n"
     ]
    }
   ],
   "source": [
    "for i in order:\n",
    "    print(frame1.loc[i]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6012, 101)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
